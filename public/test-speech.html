<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Test Speech</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 50px auto;
            padding: 20px;
        }
        button {
            padding: 15px 30px;
            font-size: 16px;
            margin: 10px;
            cursor: pointer;
        }
        .log {
            margin-top: 20px;
            padding: 20px;
            background: #f5f5f5;
            border-radius: 8px;
            max-height: 400px;
            overflow-y: auto;
        }
        .log-item {
            margin: 5px 0;
            padding: 5px;
            border-left: 3px solid #667eea;
            padding-left: 10px;
        }
    </style>
</head>
<body>
    <h1>üîä Test Ph√°t √Çm & Ghi √Çm</h1>
    
    <div>
        <h2>Test Ph√°t √Çm (Text-to-Speech)</h2>
        <button onclick="testSpeak()">Ph√°t √¢m "‰Ω†Â•Ω"</button>
        <button onclick="testSpeak2()">Ph√°t √¢m "hƒÅ l≈ç"</button>
        <button onclick="testSpeak3()">Ph√°t √¢m "Xin ch√†o"</button>
    </div>

    <div style="margin-top: 30px;">
        <h2>Test Ghi √Çm (Speech Recognition)</h2>
        <button onclick="testRecognition()">B·∫Øt ƒë·∫ßu ghi √¢m</button>
        <button onclick="stopRecognitionTest()">D·ª´ng ghi √¢m</button>
    </div>

    <div class="log" id="logArea">
        <h3>Console Log:</h3>
    </div>

    <script>
        let recognition = null;
        
        function log(message, type = 'info') {
            const logArea = document.getElementById('logArea');
            const logItem = document.createElement('div');
            logItem.className = 'log-item';
            logItem.style.borderLeftColor = type === 'error' ? '#ef4444' : type === 'success' ? '#22c55e' : '#667eea';
            logItem.textContent = `[${new Date().toLocaleTimeString()}] ${message}`;
            logArea.appendChild(logItem);
            logArea.scrollTop = logArea.scrollHeight;
            console.log(message);
        }

        function testSpeak() {
            log('üîä Testing speech synthesis with "‰Ω†Â•Ω"');
            
            if (!('speechSynthesis' in window)) {
                log('‚ùå Speech synthesis NOT supported!', 'error');
                alert('Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ ph√°t √¢m');
                return;
            }
            
            log('‚úÖ Speech synthesis is supported', 'success');
            
            try {
                window.speechSynthesis.cancel();
                
                const utterance = new SpeechSynthesisUtterance('‰Ω†Â•Ω');
                utterance.lang = 'zh-TW';
                utterance.rate = 0.8;
                
                utterance.onstart = () => log('‚úÖ Speech started', 'success');
                utterance.onend = () => log('‚úÖ Speech ended', 'success');
                utterance.onerror = (e) => log(`‚ùå Speech error: ${e.error}`, 'error');
                
                window.speechSynthesis.speak(utterance);
                log('üé§ Utterance queued for speaking');
                
            } catch (error) {
                log(`‚ùå Error: ${error.message}`, 'error');
            }
        }

        function testSpeak2() {
            log('üîä Testing speech synthesis with "hƒÅ l≈ç"');
            
            try {
                window.speechSynthesis.cancel();
                
                const utterance = new SpeechSynthesisUtterance('hƒÅ l≈ç');
                utterance.lang = 'zh-TW';
                utterance.rate = 0.8;
                
                utterance.onstart = () => log('‚úÖ Speech started', 'success');
                utterance.onend = () => log('‚úÖ Speech ended', 'success');
                utterance.onerror = (e) => log(`‚ùå Speech error: ${e.error}`, 'error');
                
                window.speechSynthesis.speak(utterance);
                log('üé§ Utterance queued for speaking');
                
            } catch (error) {
                log(`‚ùå Error: ${error.message}`, 'error');
            }
        }

        function testSpeak3() {
            log('üîä Testing speech synthesis with "Xin ch√†o"');
            
            try {
                window.speechSynthesis.cancel();
                
                const utterance = new SpeechSynthesisUtterance('Xin ch√†o');
                utterance.lang = 'vi-VN';
                utterance.rate = 0.8;
                
                utterance.onstart = () => log('‚úÖ Speech started', 'success');
                utterance.onend = () => log('‚úÖ Speech ended', 'success');
                utterance.onerror = (e) => log(`‚ùå Speech error: ${e.error}`, 'error');
                
                window.speechSynthesis.speak(utterance);
                log('üé§ Utterance queued for speaking');
                
            } catch (error) {
                log(`‚ùå Error: ${error.message}`, 'error');
            }
        }

        async function testRecognition() {
            log('üéôÔ∏è Testing speech recognition');
            
            if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
                log('‚ùå Speech recognition NOT supported!', 'error');
                alert('Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ nh·∫≠n di·ªán gi·ªçng n√≥i');
                return;
            }
            
            log('‚úÖ Speech recognition is supported', 'success');
            
            try {
                // Request microphone permission
                log('üì± Requesting microphone permission...');
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                stream.getTracks().forEach(track => track.stop());
                log('‚úÖ Microphone permission granted', 'success');
                
                // Initialize recognition
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                recognition = new SpeechRecognition();
                recognition.lang = 'zh-TW';
                recognition.continuous = false;
                recognition.interimResults = false;
                
                recognition.onstart = () => {
                    log('‚úÖ Recognition started - please speak!', 'success');
                };
                
                recognition.onresult = (event) => {
                    const transcript = event.results[0][0].transcript;
                    const confidence = event.results[0][0].confidence;
                    log(`‚úÖ Recognized: "${transcript}" (confidence: ${(confidence * 100).toFixed(1)}%)`, 'success');
                };
                
                recognition.onerror = (event) => {
                    log(`‚ùå Recognition error: ${event.error}`, 'error');
                };
                
                recognition.onend = () => {
                    log('‚úÖ Recognition ended', 'success');
                };
                
                recognition.start();
                log('üé§ Recognition started, waiting for speech...');
                
            } catch (error) {
                log(`‚ùå Error: ${error.message}`, 'error');
            }
        }

        function stopRecognitionTest() {
            if (recognition) {
                recognition.stop();
                log('üõë Stopping recognition...');
            } else {
                log('‚ö†Ô∏è No active recognition to stop', 'error');
            }
        }

        // Log browser info
        log(`Browser: ${navigator.userAgent}`);
        log(`Speech Synthesis: ${('speechSynthesis' in window) ? '‚úÖ Supported' : '‚ùå Not supported'}`);
        log(`Speech Recognition: ${('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) ? '‚úÖ Supported' : '‚ùå Not supported'}`);
    </script>
</body>
</html>
